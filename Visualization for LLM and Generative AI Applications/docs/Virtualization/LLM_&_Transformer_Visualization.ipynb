{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit\n",
        "!pip install pymupdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsO9l57rS__5",
        "outputId": "67a3e2f5-a4a1-46eb-ea7b-9ae33a128a1d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.43.2-py2.py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.1.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.25.6)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.12.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m812.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.30.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.1.31)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.23.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.43.2-py2.py3-none-any.whl (9.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.43.2 watchdog-6.0.0\n",
            "Collecting pymupdf\n",
            "  Downloading pymupdf-1.25.4-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading pymupdf-1.25.4-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymupdf\n",
            "Successfully installed pymupdf-1.25.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuCgolkiS8yQ",
        "outputId": "395fa73a-5988-4d63-cebe-786c7519b8c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import fitz  # PyMuPDF for PDF text extraction\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "\n",
        "# Hugging Face API Key (Replace with your key)\n",
        "HUGGINGFACE_API_KEY = \"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\"\n",
        "\n",
        "# Load Hugging Face Model for AI Chatbot using API\n",
        "@st.cache_resource\n",
        "def load_chatbot():\n",
        "    try:\n",
        "        tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-1.3b\", use_auth_token=HUGGINGFACE_API_KEY)\n",
        "        model = AutoModelForCausalLM.from_pretrained(\"facebook/opt-1.3b\", use_auth_token=HUGGINGFACE_API_KEY)\n",
        "        st.success(\"Loaded OPT-1.3B model successfully!\")\n",
        "        return pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
        "    except Exception as e:\n",
        "        st.warning(f\"OPT-1.3B failed to load. Using smaller model (DistilGPT-2). Error: {e}\")\n",
        "        try:\n",
        "            tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\")\n",
        "            model = AutoModelForCausalLM.from_pretrained(\"distilgpt2\")\n",
        "            return pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
        "        except Exception as e:\n",
        "            st.error(f\"Chatbot failed to load: {e}\")\n",
        "            return None\n",
        "\n",
        "chatbot = load_chatbot()\n",
        "\n",
        "def generate_ai_response(query):\n",
        "    \"\"\"Generates a response using Hugging Face model with error handling.\"\"\"\n",
        "    if chatbot:\n",
        "        try:\n",
        "            response = chatbot(query, max_length=200, do_sample=True)\n",
        "            return response[0]['generated_text'].strip()\n",
        "        except requests.exceptions.Timeout:\n",
        "            return \"Error: Request timed out. Try again.\"\n",
        "        except Exception as e:\n",
        "            return f\"Error: {e}\"\n",
        "    return \"Chatbot is unavailable.\"\n",
        "\n",
        "# Title of the Application\n",
        "st.title(\"AI-Powered Supply Chain Resilience Index (SCRI)\")\n",
        "\n",
        "# Sidebar for file uploads\n",
        "st.sidebar.header(\"Upload Your Datasets\")\n",
        "customer_file = st.sidebar.file_uploader(\"Upload Customer Dataset (CSV)\", type=[\"csv\"])\n",
        "logistic_file = st.sidebar.file_uploader(\"Upload Logistic Dataset (CSV)\", type=[\"csv\"])\n",
        "retail_file = st.sidebar.file_uploader(\"Upload Retail Dataset (CSV)\", type=[\"csv\"])\n",
        "\n",
        "# Function to load and display datasets\n",
        "@st.cache_data\n",
        "def load_data(file, name):\n",
        "    if file is not None:\n",
        "        try:\n",
        "            df = pd.read_csv(file, low_memory=False)\n",
        "            st.subheader(f\"{name} Preview\")\n",
        "            st.write(df.head())\n",
        "            return df\n",
        "        except Exception as e:\n",
        "            st.error(f\"Error loading {name}: {e}\")\n",
        "    return None\n",
        "\n",
        "# Load datasets\n",
        "customer_df = load_data(customer_file, \"Customer Dataset\")\n",
        "logistic_df = load_data(logistic_file, \"Logistic Dataset\")\n",
        "retail_df = load_data(retail_file, \"Retail Dataset\")\n",
        "\n",
        "# Risk Analysis Section\n",
        "st.header(\"Supply Chain Risk Analysis\")\n",
        "if logistic_df is not None:\n",
        "    st.subheader(\"Logistic Risk Insights\")\n",
        "    if \"delays\" in logistic_df.columns:\n",
        "        fig = px.histogram(logistic_df, x=\"delays\", title=\"Logistic Delays Distribution\")\n",
        "        st.plotly_chart(fig)\n",
        "\n",
        "if retail_df is not None:\n",
        "    st.subheader(\"Retail Supply Chain Risks\")\n",
        "    if \"inventory_levels\" in retail_df.columns:\n",
        "        fig = px.line(retail_df, x=retail_df.index, y=\"inventory_levels\", title=\"Retail Inventory Levels Over Time\")\n",
        "        st.plotly_chart(fig)\n",
        "\n",
        "# AI Chat Interface with Hugging Face Model\n",
        "st.header(\"AI Chatbot - Ask About Supply Chain Risks\")\n",
        "user_query = st.text_input(\"Enter your question about supply chain risks:\")\n",
        "if user_query:\n",
        "    response = generate_ai_response(user_query)\n",
        "    st.write(f\"**AI Response:** {response}\")\n",
        "\n",
        "# RAG-based Document Upload & Retrieval\n",
        "st.header(\"Upload and Retrieve Risk Reports\")\n",
        "report_file = st.file_uploader(\"Upload Supply Chain Risk Report (PDF)\", type=[\"pdf\"])\n",
        "\n",
        "def extract_text_from_pdf(uploaded_file):\n",
        "    \"\"\"Extracts text from uploaded PDF.\"\"\"\n",
        "    doc = fitz.open(stream=uploaded_file.read(), filetype=\"pdf\")\n",
        "    text = \"\".join([page.get_text(\"text\") for page in doc])\n",
        "    return text\n",
        "\n",
        "if report_file:\n",
        "    st.success(\"Report uploaded successfully! AI will analyze and retrieve insights.\")\n",
        "    extracted_text = extract_text_from_pdf(report_file)\n",
        "\n",
        "    if extracted_text:\n",
        "        st.subheader(\"Extracted Insights from Report\")\n",
        "        st.text_area(\"\", extracted_text[:2000])  # Display first 2000 characters\n",
        "    else:\n",
        "        st.error(\"No readable text found in the document.\")\n",
        "\n",
        "# Improved Image Generation using Matplotlib for Supply Chain Visualizations\n",
        "st.header(\"Generate Supply Chain Risk Visualizations\")\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def generate_visualization(prompt):\n",
        "    fig, ax = plt.subplots(figsize=(6, 6))\n",
        "    ax.set_title(\"Supply Chain Risk Analysis\", fontsize=14)\n",
        "    ax.barh([\"Weather Impact\", \"Logistics Delay\", \"Supplier Risk\", \"Inventory Shortage\"],\n",
        "            [30, 45, 20, 35], color=['red', 'orange', 'blue', 'green'])\n",
        "    ax.set_xlabel(\"Risk Level (%)\")\n",
        "    ax.set_ylabel(\"Risk Factors\")\n",
        "    return fig\n",
        "\n",
        "image_prompt = st.text_input(\"Enter a description for the risk visualization image:\")\n",
        "if image_prompt:\n",
        "    fig = generate_visualization(image_prompt)\n",
        "    st.pyplot(fig)\n",
        "\n",
        "st.sidebar.info(\"Built with Streamlit for interactive AI-powered supply chain risk analysis.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok http 8501\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kx5VgbPPdizE",
        "outputId": "5641b5c6-c101-4b2b-b243-5a3d61074127"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: ngrok: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmXaGMtPTLT9",
        "outputId": "99037631-4386-43ec-f2cf-d1df25b66afe"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8502\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8502\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.196.57.75:8502\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06LOICEOTO_J",
        "outputId": "298f83b8-598f-4e39-c586-98326af6ec09"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.3)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "import os\n",
        "\n",
        "\n",
        "ngrok.set_auth_token(\"2svEijc2vzFgz33NDuZwlBEfdjL_7sJudSucFk2B48JkFayyZ\")\n",
        "# Kill existing processes to prevent tunnel conflicts\n",
        "os.system(\"pkill -f ngrok\")\n",
        "\n",
        "# Start Streamlit in the background\n",
        "os.system(\"streamlit run app.py --server.port 8501 &\")\n",
        "\n",
        "# Open an ngrok tunnel\n",
        "public_url = ngrok.connect(8501)\n",
        "print(f\"Streamlit is live at: {public_url}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-z-92KjdQkn",
        "outputId": "50027f3c-3df8-4aa4-e780-a5f91d92c376"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamlit is live at: NgrokTunnel: \"https://1910-35-196-57-75.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    }
  ]
}